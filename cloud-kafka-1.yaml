Parameters:
    MySubnetID:
        Description: Subnet IDs that is a List of Subnet Id
        Type: 'AWS::EC2::Subnet::Id'
        Default: "subnet-2aed9467"
    KeyName:
        Description: 'For SSH access'
        Type: 'AWS::EC2::KeyPair::KeyName'
    SSHLocation:
        Description: The IP address range that can be used to SSH to the EC2 instances
        Type: String
        MinLength: '9'
        MaxLength: '18'
        Default: 0.0.0.0/0
        AllowedPattern: "(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})"
        ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.
Resources:
    EC2SecurityGroup:
        Type: "AWS::EC2::SecurityGroup"
        Properties:
            GroupDescription: "kafka security group"
            GroupName: "Kafka-zookeeper"
            VpcId: "vpc-a3c702de"
            SecurityGroupIngress: 
              - 
                CidrIp: "172.31.0.0/16"
                FromPort: 2888
                IpProtocol: "tcp"
                ToPort: 2888
              - 
                CidrIp: !Ref SSHLocation
                FromPort: 22
                IpProtocol: "tcp"
                ToPort: 22
              - 
                CidrIp: "172.31.0.0/16"
                FromPort: 3888
                IpProtocol: "tcp"
                ToPort: 3888
              - 
                CidrIp: "172.31.0.0/16"
                FromPort: 2181
                IpProtocol: "tcp"
                ToPort: 2181
              - 
                CidrIp: !Ref SSHLocation
                FromPort: 2181
                IpProtocol: "tcp"
                ToPort: 2181
              - 
                CidrIp: "172.31.0.0/16"
                FromPort: 9092
                IpProtocol: "tcp"
                ToPort: 9092
              - 
                CidrIp: !Ref SSHLocation
                FromPort: 9092
                IpProtocol: "tcp"
                ToPort: 9092
            SecurityGroupEgress: 
              - 
                CidrIp: "0.0.0.0/0"
                IpProtocol: "-1"

    EC2SecurityGroup2:
        Type: "AWS::EC2::SecurityGroup"
        Properties:
            GroupDescription: "kafkacompose"
            GroupName: "launch-wizard-1"
            VpcId: "vpc-a3c702de"
            SecurityGroupIngress: 
              - 
                CidrIp: !Ref SSHLocation
                FromPort: 9000
                IpProtocol: "tcp"
                ToPort: 9000
              - 
                CidrIp: !Ref SSHLocation
                FromPort: 8001
                IpProtocol: "tcp"
                ToPort: 8001
              - 
                CidrIp: !Ref SSHLocation
                FromPort: 22
                IpProtocol: "tcp"
                ToPort: 22
            SecurityGroupEgress: 
              - 
                CidrIp: "0.0.0.0/0"
                IpProtocol: "-1"
    EC2Instance:
        Type: "AWS::EC2::Instance"
        Properties:
            ImageId: "ami-0817d428a6fb68645"
            InstanceType: "t2.medium"
            KeyName: !Ref KeyName
            AvailabilityZone: !Sub "${AWS::Region}a"
            #SecurityGroupIds: 
              #- !Ref EC2SecurityGroup
            NetworkInterfaces:
              -
                NetworkInterfaceId: !Ref myENI
                DeviceIndex: 0
            SourceDestCheck: true
            BlockDeviceMappings: 
              - 
                DeviceName: "/dev/sda1"
                Ebs: 
                    Encrypted: false
                    VolumeSize: 8
                    VolumeType: "gp2"
                    DeleteOnTermination: true
              - 
                DeviceName: "/dev/sdf"
                Ebs: 
                    Encrypted: false
                    VolumeSize: 2
                    VolumeType: "gp2"
                    DeleteOnTermination: true
            Tags: 
              - 
                Key: "Name"
                Value: "Server 1"
            HibernationOptions: 
                Configured: false
                
                 
            UserData:
              Fn::Base64: !Sub |
                 #!/bin/bash -xe
                 sudo apt-get update -y

                 sudo apt-get install python-setuptools -y 

                 sudo apt-get install python.pip -y

                 sudo apt-get -y install wget ca-certificates zip net-tools vim nano tar netcat

                 sudo apt-get install openjdk-8-jdk -y

                 apt-get install xfsprogs -y

                 sudo sysctl vm.swappiness=1

                 echo 'vm.swappiness=1' | sudo tee --append /etc/sysctl.conf
                 #172.31.9.1 kafka2
                 #172.31.9.1 zookeeper2

                 #172.31.32.20 kafka3
                 #172.31.32.20 zookeeper3

                 echo "172.31.16.10 kafka1
                 172.31.16.10 zookeeper1" | sudo tee --append /etc/hosts

                 sudo mkdir -p /opt/aws/bin
                 
                 wget https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz

                 python -m easy_install --script-dir /opt/aws/bin aws-cfn-bootstrap-latest.tar.gz


                 wget https://mirrors.estointernet.in/apache/kafka/2.6.0/kafka_2.12-2.6.0.tgz

                 sudo tar -xzf kafka_2.12-2.6.0.tgz

                 sudo rm kafka_2.12-2.6.0.tgz

                 sudo mv kafka_2.12-2.6.0 kafka

                 sudo chown -R ubuntu:ubuntu /kafka

                 sudo apt-get update -y

                 sleep 30

                 # create data dictionary for zookeeper
                  sudo mkdir -p /data/zookeeper

                  sudo chown -R ubuntu:ubuntu /data/

                  echo "1" > /data/zookeeper/myid

                 sudo fdisk /dev/xvdf
                 sudo mkfs.xfs -f /dev/xvdf
                 sudo mkdir  /data/kafka
                 sudo mount -t xfs /dev/xvdf /data/kafka
                 sudo chown -R ubuntu:ubuntu /data/kafka

                 # EBS Automount On Reboot
                  sudo su <<EOF
                  cp /etc/fstab /etc/fstab.bak
                  echo '/dev/xvdf /data/kafka xfs defaults 0 0' >> /etc/fstab
                  EOF

                  echo "* hard nofile 100000
                  * soft nofile 100000" | sudo tee --append /etc/security/limits.conf
                  
                  #new zookeeper settings
                  rm kafka/config/zookeeper.properties
                  #new kafka server settings
                  sudo rm kafka/config/server.properties


                 /opt/aws/bin/cfn-init -s ${AWS::StackId} -r EC2Instance --configsets oneand2 --region ${AWS::Region} || error_exit 'failed to run cfn-init'
                 
                 # Start up the cfn-hup daemon to listen for changes to the EC2 instance metadata

                  /opt/aws/bin/cfn-hup || error_exit 'Failed to start cfn-hup'

                  ( cd /kafka ; sudo chmod +x /etc/init.d/zookeeper )

                  ( cd /kafka ; sudo chown root:root /etc/init.d/zookeeper )

                  ( cd /kafka ; sudo update-rc.d zookeeper defaults )

                  ( cd /kafka ; sudo service zookeeper stop )

                  ( cd /kafka ; sudo service zookeeper start )

                  ( cd /kafka ; sudo chmod +x /etc/init.d/kafka )
                  ( cd /kafka ; sudo chown root:root /etc/init.d/kafka )
                  ( cd /kafka ; sudo update-rc.d kafka defaults )
                  ( cd /kafka ; sudo service kafka start )

                  # All done so signal success

                  /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackId} --resource EC2Instance --region ${AWS::Region}
                
        Metadata:
          AWS::CloudFormation::Init:
            configSets:
              oneand2:
                - set1
                - set2
            set1:
              files:
                "/kafka/config/zookeeper.properties":
                  content: |
                    # the location to store the in-memory database snapshots and, unless specified otherwise, the transaction log of updates to the database.
                    dataDir=/data/zookeeper
                    # the port at which the clients will connect
                    clientPort=2181
                    # disable the per-ip limit on the number of connections since this is a non-production config
                     maxClientCnxns=0
                     # the basic time unit in milliseconds used by ZooKeeper. It is used to do heartbeats and the minimum session timeout will be twice the tickTime.
                    tickTime=2000
                    # The number of ticks that the initial synchronization phase can take
                    initLimit=10
                    # The number of ticks that can pass between
                    # sending a request and getting an acknowledgement
                    syncLimit=5
                    # zoo servers
                    # these hostnames such as `zookeeper-1` come from the /etc/hosts file
                    server.1=zookeeper1:2888:3888
                    #server.2=zookeeper2:2888:3888
                    #server.3=zookeeper3:2888:3888
                    4lw.commands.whitelist=*
                  encoding: plain
                  group: ubuntu
                  owner: ubuntu
                  mode: "000755"
                "/kafka/config/server.properties":
                  content: |
                    ############################# Server Basics #############################

                    # The id of the broker. This must be set to a unique integer for each broker.

                    broker.id=0

                    # change your.host.name by your machine's IP or hostname

                    advertised.listeners=PLAINTEXT://kafka1:9092

                    # Switch to enable topic deletion or not, default value is false

                    delete.topic.enable=true


                    ############################# Log Basics #############################

                    # A comma seperated list of directories under which to store log files

                    log.dirs=/data/kafka

                    # The default number of log partitions per topic. More partitions allow greater
                    # parallelism for consumption, but this will also result in more files across
                    # the brokers.
                    num.partitions=8
                    # we will have 3 brokers so the default replication factor should be 2 or 3
                    default.replication.factor=1
                    
                    #Replication factor to be set to 1 when using a single node kafka, 3 for clusture , default is 3
                    # number of ISR to have in order to minimize data loss
                    min.insync.replicas=1

                    ############################# Log Retention Policy #############################

                    # The minimum age of a log file to be eligible for deletion due to age
                    # this will delete data after a week
                    log.retention.hours=168

                    # The maximum size of a log segment file. When this size is reached a new log segment will be created.
                    log.segment.bytes=1073741824

                    # The interval at which log segments are checked to see if they can be deleted according
                    # to the retention policies
                    log.retention.check.interval.ms=300000

                    ############################# Zookeeper #############################

                    # Zookeeper connection string (see zookeeper docs for details).
                    # This is a comma separated host:port pairs, each corresponding to a zk
                    # server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
                    # You can also append an optional chroot string to the urls to specify the
                    # root directory for all kafka znodeszookeeper2:2181,zookeeper3:2181

                    zookeeper.connect=zookeeper1:2181/kafka

                    # Timeout in ms for connecting to zookeeper
                    zookeeper.connection.timeout.ms=6000


                    ############################## Other ##################################
                    # I recommend you set this to false in production.
                    # We'll keep it as true for the course
                    auto.create.topics.enable=true
                  encoding: plain
                  mode: "000755"
                  owner: ubuntu
                  group: ubuntu

                "/etc/cfn/cfn-hup.conf":
                  content: !Sub |
                    [main]
                    stack=${AWS::StackId}
                    region=${AWS::Region}
                  mode: "000400"
                  owner: "root"
                  group: "root"
                "/etc/cfn/hooks.d/cfn-auto-reloader.conf":
                  content: !Sub |
                    [cfn-auto-reloader-hook]
                    triggers=post.update
                    path=Resources.EC2Instance.Metadata.AWS::CloudFormation::Init
                    action=/opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource EC2Instance --region ${AWS::Region}
                  mode: "000400"
                  owner: "root"
                  group: "root"
            set2:
              commands:
                test3:
                  command: "bin/zookeeper-server-start.sh -daemon config/zookeeper.properties"
                  cwd: "/kafka"

              files:
                "/etc/init.d/zookeeper":
                  content: |
                      #!/bin/sh -xe
                      #
                      # zookeeper          Start/Stop zookeeper
                      #
                      # chkconfig: - 99 10
                      # description: Standard script to start and stop zookeeper

                      DAEMON_PATH=/kafka/bin
                      DAEMON_NAME=zookeeper

                      PATH=$PATH:$DAEMON_PATH

                      # See how we were called.
                      case "$1" in
                        start)
                              # Start daemon.
                              pid=`ps ax | grep -i 'org.apache.zookeeper' | grep -v grep | awk '{print $1}'`
                              if [ -n "$pid" ]
                                then
                                  echo "Zookeeper is already running";
                              else
                                echo "Starting $DAEMON_NAME";
                                $DAEMON_PATH/zookeeper-server-start.sh -daemon kafka/config/zookeeper.properties
                              fi
                              ;;
                        stop)
                              echo "Shutting down $DAEMON_NAME";
                              $DAEMON_PATH/zookeeper-server-stop.sh
                              ;;
                        restart)
                              $0 stop
                              sleep 2
                              $0 start
                              ;;
                        status)
                              pid=`ps ax | grep -i 'org.apache.zookeeper' | grep -v grep | awk '{print $1}'`
                              if [ -n "$pid" ]
                                then
                                echo "Zookeeper is Running as PID: $pid"
                              else
                                echo "Zookeeper is not Running"
                              fi
                              ;;
                        *)
                              echo "Usage: $0 {start|stop|restart|status}"
                              exit 1
                      esac

                      exit 0
                  owner: ubuntu
                  group: ubuntu
                  mode:  "000777"
                "/etc/init.d/kafka":
                  content: |
                    #!/bin/bash -xe
                    #/etc/init.d/kafka
                    DAEMON_PATH=/kafka/bin
                    DAEMON_NAME=kafka
                    # Check that networking is up.
                    #[ ${NETWORKING} = "no" ] && exit 0

                    PATH=$PATH:$DAEMON_PATH

                    # See how we were called.
                    case "$1" in
                      start)
                            # Start daemon.
                            pid=`ps ax | grep -i 'kafka.Kafka' | grep -v grep | awk '{print $1}'`
                            if [ -n "$pid" ]
                              then
                                echo "Kafka is already running"
                            else
                              echo "Starting $DAEMON_NAME"
                              $DAEMON_PATH/kafka-server-start.sh -daemon /kafka/config/server.properties
                            fi
                            ;;
                      stop)
                            echo "Shutting down $DAEMON_NAME"
                            $DAEMON_PATH/kafka-server-stop.sh
                            ;;
                      restart)
                            $0 stop
                            sleep 2
                            $0 start
                            ;;
                      status)
                            pid=`ps ax | grep -i 'kafka.Kafka' | grep -v grep | awk '{print $1}'`
                            if [ -n "$pid" ]
                              then
                              echo "Kafka is Running as PID: $pid"
                            else
                              echo "Kafka is not Running"
                            fi
                            ;;
                      *)
                            echo "Usage: $0 {start|stop|restart|status}"
                            exit 1
                    esac

                    exit 0
                  owner: ubuntu
                  group: ubuntu
                  mode: "000777"


          CreationPolicy:
            ResourceSignal:
              Timeout: PT2M
    myENI:
      Type: AWS::EC2::NetworkInterface
      Properties:
         Description: Private IP for server 1
         SourceDestCheck: 'false'
         GroupSet:
         - !Ref EC2SecurityGroup
         SubnetId: !Ref MySubnetID
         PrivateIpAddress: 172.31.16.10

    
